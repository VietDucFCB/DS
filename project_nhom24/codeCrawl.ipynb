{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34eb5635-07f1-44a7-9e90-200b5936f94c",
   "metadata": {},
   "source": [
    "Dưới đây là phiên bản code hoàn chỉnh về việc cào dữ liệu từ web và quy trinh hoạt động của nó:\n",
    "1. Khởi tạo môi trường và các thư viện cần thiết\n",
    "2. Thiết lập thư mục lưu trữ:\n",
    "    - Định nghĩa biến output_dir là đường dẫn đến thư mục lưu trữ dữ liệu đã crawl.\n",
    "    - Kiểm tra và tạo thư mục output_dir nếu nó chưa tồn tại.\n",
    "3. Khởi tạo trình duyệt Edge với Selenium:\n",
    "    - Định nghĩa hàm get_driver() để khởi tạo trình duyệt Edge với đường dẫn đến msedgedriver.exe.\n",
    "4. Hàm extract_and_save_house_data(page_number):\n",
    "    - Hàm này nhận đầu vào là số trang page_number và sử dụng Selenium để điều hướng đến từng trang web bất động sản.\n",
    "    - Thu thập mã nguồn HTML của trang bằng cách sử dụng driver.page_source.\n",
    "    - Sử dụng BeautifulSoup để phân tích cú pháp HTML và trích xuất thông tin nhà từ các thẻ HTML tương ứng.\n",
    "    - Dữ liệu cụ thể được trích xuất bao gồm: tiêu đề, giá, diện tích, số phòng ngủ, số phòng tắm, địa chỉ, mã tin, ngày đăng, và nội dung tin đăng.\n",
    "    - Dữ liệu sau khi trích xuất được lưu vào các tệp văn bản .txt trong thư mục output_dir. Mỗi trang web sẽ có một thư mục con và mỗi bài viết sẽ có một tệp tin riêng.\n",
    "    - Nếu có lỗi xảy ra trong quá trình xử lý, hàm sẽ bắt và in ra thông báo lỗi, sau đó sẽ thoát và đóng trình duyệt để tránh rò rỉ bộ nhớ.\n",
    "5. Vòng lặp chính:\n",
    "    - Sử dụng ThreadPoolExecutor để thực thi extract_and_save_house_data(page_number) cho mỗi trang từ 1 đến total_pages.\n",
    "    - Với mỗi future được hoàn thành (as_completed), kiểm tra kết quả và in thông báo nếu có lỗi xảy ra trong quá trình xử lý một trang.\n",
    "\n",
    "**Lợi ích:** Tự động hóa quy trình thu thập dữ liệu từ trang web, tiết kiệm thời gian và công sức so với việc thủ công. Thu thập thông tin chi tiết và cụ thể về các bất động sản như tiêu đề, giá cả, diện tích, và các thông tin khác. Tạo ra một cơ sở dữ liệu văn bản dễ dàng quản lý và phân tích.\n",
    "\n",
    "**Hạn chế:** Việc cào dữ liệu này mất rất nhiều thời gian cần được giám sát liên tục đề phòng có lỗi xảy ra\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3b3458a-b21d-4848-9ff0-2bf7b158be30",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đang lấy dữ liệu từ trang 3...\n",
      "Tìm thấy 20 hrefs trên trang 3.\n",
      "Đang xử lý href 1/20: https://batdongsan.vn/gap-ban-giam-13-ty-nha-quan-3-60m2-ngang-5m-chi-5x-ty-r284992\n",
      "Đã lưu dữ liệu từ bài viết https://batdongsan.vn/gap-ban-giam-13-ty-nha-quan-3-60m2-ngang-5m-chi-5x-ty-r284992 vào tệp data_crawled_batdongsan\\3\\1.txt\n",
      "Đang xử lý href 2/20: https://batdongsan.vn/ban-nha-go-vap-hxt-tranh-nguyen-van-khoi-p11-58m2-5-tang-chi-97-ty-r284982\n",
      "Đã lưu dữ liệu từ bài viết https://batdongsan.vn/ban-nha-go-vap-hxt-tranh-nguyen-van-khoi-p11-58m2-5-tang-chi-97-ty-r284982 vào tệp data_crawled_batdongsan\\3\\2.txt\n",
      "Đang xử lý href 3/20: https://batdongsan.vn/ban-nha-moi-4-tang-hxh-1-duong-tinh-lo-10-binh-tri-dong-binh-tan-48m2-nhinh-4ty-r284979\n",
      "Đã lưu dữ liệu từ bài viết https://batdongsan.vn/ban-nha-moi-4-tang-hxh-1-duong-tinh-lo-10-binh-tri-dong-binh-tan-48m2-nhinh-4ty-r284979 vào tệp data_crawled_batdongsan\\3\\3.txt\n",
      "Đang xử lý href 4/20: https://batdongsan.vn/ban-nha-mat-tien-duong-nhua-18m-an-phu-q2-16-ty-4x20m-4-tang-thich-hop-lam-van-phong-r284978\n",
      "Đã lưu dữ liệu từ bài viết https://batdongsan.vn/ban-nha-mat-tien-duong-nhua-18m-an-phu-q2-16-ty-4x20m-4-tang-thich-hop-lam-van-phong-r284978 vào tệp data_crawled_batdongsan\\3\\4.txt\n",
      "Đang xử lý href 5/20: https://batdongsan.vn/nha-ban-2-tang-hiep-binh-chanh-ngay-gan-song-sg-vong-xoay-binh-trieu-r284975\n",
      "Đã lưu dữ liệu từ bài viết https://batdongsan.vn/nha-ban-2-tang-hiep-binh-chanh-ngay-gan-song-sg-vong-xoay-binh-trieu-r284975 vào tệp data_crawled_batdongsan\\3\\5.txt\n",
      "Đang xử lý href 6/20: https://batdongsan.vn/sieu-hot-ly-thanh-tong-tan-phu-ngang-4m-75m2-chi-8-ty-hon-r284973\n",
      "Đã lưu dữ liệu từ bài viết https://batdongsan.vn/sieu-hot-ly-thanh-tong-tan-phu-ngang-4m-75m2-chi-8-ty-hon-r284973 vào tệp data_crawled_batdongsan\\3\\6.txt\n",
      "Đang xử lý href 7/20: https://batdongsan.vn/sieu-hot-ly-thanh-tong-tan-phu-ngang-4m-75m2-chi-8-ty-hon-r284972\n",
      "Đã lưu dữ liệu từ bài viết https://batdongsan.vn/sieu-hot-ly-thanh-tong-tan-phu-ngang-4m-75m2-chi-8-ty-hon-r284972 vào tệp data_crawled_batdongsan\\3\\7.txt\n",
      "Đang xử lý href 8/20: https://batdongsan.vn/quan-7-thong-so-cuc-dep-4x13m-cach-1-can-ra-o-to-r284971\n",
      "Đã lưu dữ liệu từ bài viết https://batdongsan.vn/quan-7-thong-so-cuc-dep-4x13m-cach-1-can-ra-o-to-r284971 vào tệp data_crawled_batdongsan\\3\\8.txt\n",
      "Đang xử lý href 9/20: https://batdongsan.vn/ban-nha-go-vap-hxt-tranh-quang-trung-phuong-8-57m2-5-tang-chi-109-ty-r284968\n",
      "Đã lưu dữ liệu từ bài viết https://batdongsan.vn/ban-nha-go-vap-hxt-tranh-quang-trung-phuong-8-57m2-5-tang-chi-109-ty-r284968 vào tệp data_crawled_batdongsan\\3\\9.txt\n",
      "Đang xử lý href 10/20: https://batdongsan.vn/hxh-huong-lo-2-btd-binh-tan-300m2-4-tang-kinh-doanh-chdv-xuong-gia-nhinh-135-ty-r284964\n",
      "Đã lưu dữ liệu từ bài viết https://batdongsan.vn/hxh-huong-lo-2-btd-binh-tan-300m2-4-tang-kinh-doanh-chdv-xuong-gia-nhinh-135-ty-r284964 vào tệp data_crawled_batdongsan\\3\\10.txt\n",
      "Đang xử lý href 11/20: https://batdongsan.vn/connect-to-success-facebook-ads-bringing-brands-to-the-right-audience-r284956\n",
      "Đã lưu dữ liệu từ bài viết https://batdongsan.vn/connect-to-success-facebook-ads-bringing-brands-to-the-right-audience-r284956 vào tệp data_crawled_batdongsan\\3\\11.txt\n",
      "Đang xử lý href 12/20: https://batdongsan.vn/nha-rong-o-to-do-cua-va-vao-trong-canh-cc-bau-cat-49-ty-r284952\n",
      "Đã lưu dữ liệu từ bài viết https://batdongsan.vn/nha-rong-o-to-do-cua-va-vao-trong-canh-cc-bau-cat-49-ty-r284952 vào tệp data_crawled_batdongsan\\3\\12.txt\n",
      "Đang xử lý href 13/20: https://batdongsan.vn/ban-nha-hem-4m-pham-van-chieu-phuong-14-go-vap-50m2-2-tang-chi-47-ty-r284950\n",
      "Đã lưu dữ liệu từ bài viết https://batdongsan.vn/ban-nha-hem-4m-pham-van-chieu-phuong-14-go-vap-50m2-2-tang-chi-47-ty-r284950 vào tệp data_crawled_batdongsan\\3\\13.txt\n",
      "Đang xử lý href 14/20: https://batdongsan.vn/ban-nha-mat-tien-duong-so-4-phuong-11-go-vap-42m2-4-tang-chi-625-ty-r284947\n",
      "Đã lưu dữ liệu từ bài viết https://batdongsan.vn/ban-nha-mat-tien-duong-so-4-phuong-11-go-vap-42m2-4-tang-chi-625-ty-r284947 vào tệp data_crawled_batdongsan\\3\\14.txt\n",
      "Đang xử lý href 15/20: https://batdongsan.vn/pham-van-hai-hxh-1-xec-gan-truong-sa-dtsd-88m2-5-ty-r284945\n",
      "Đã lưu dữ liệu từ bài viết https://batdongsan.vn/pham-van-hai-hxh-1-xec-gan-truong-sa-dtsd-88m2-5-ty-r284945 vào tệp data_crawled_batdongsan\\3\\15.txt\n",
      "Đang xử lý href 16/20: https://batdongsan.vn/hxh-quang-trung-phuong-11-thong-tu-tung-2-lau-85m2-75-ty-r284942\n",
      "Đã lưu dữ liệu từ bài viết https://batdongsan.vn/hxh-quang-trung-phuong-11-thong-tu-tung-2-lau-85m2-75-ty-r284942 vào tệp data_crawled_batdongsan\\3\\16.txt\n",
      "Đang xử lý href 17/20: https://batdongsan.vn/ban-nha-binh-tan-ke-mt-go-xoai-3-tang-4x20m-kinh-doanh-binh-tan-r284927\n",
      "Đã lưu dữ liệu từ bài viết https://batdongsan.vn/ban-nha-binh-tan-ke-mt-go-xoai-3-tang-4x20m-kinh-doanh-binh-tan-r284927 vào tệp data_crawled_batdongsan\\3\\17.txt\n",
      "Đang xử lý href 18/20: https://batdongsan.vn/ban-nha-duong-vuon-lai-phu-tho-hoa-tan-phu-r284914\n",
      "Đã lưu dữ liệu từ bài viết https://batdongsan.vn/ban-nha-duong-vuon-lai-phu-tho-hoa-tan-phu-r284914 vào tệp data_crawled_batdongsan\\3\\18.txt\n",
      "Đang xử lý href 19/20: https://batdongsan.vn/nha-mat-tien-sat-duong-to-ngoc-van-p-tam-binh-dt-121-m-gia-74tr-m-r284908\n",
      "Đã lưu dữ liệu từ bài viết https://batdongsan.vn/nha-mat-tien-sat-duong-to-ngoc-van-p-tam-binh-dt-121-m-gia-74tr-m-r284908 vào tệp data_crawled_batdongsan\\3\\19.txt\n",
      "Đang xử lý href 20/20: https://batdongsan.vn/gia-cua-nhua-composite-cua-nhua-abs-va-cua-nhua-dai-loan-r284906\n",
      "Đã lưu dữ liệu từ bài viết https://batdongsan.vn/gia-cua-nhua-composite-cua-nhua-abs-va-cua-nhua-dai-loan-r284906 vào tệp data_crawled_batdongsan\\3\\20.txt\n",
      "Quá trình thu thập dữ liệu đã hoàn tất.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.edge.service import Service as EdgeService\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Đường dẫn đến thư mục lưu trữ dữ liệu đã crawl\n",
    "output_dir = \"data_crawled_batdongsan\"\n",
    "\n",
    "# Tạo thư mục nếu chưa tồn tại\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# Khởi tạo EdgeDriver mà không có tùy chọn nào.\n",
    "def get_driver():\n",
    "    edge_driver_path = \"C:/EdgeDriver/msedgedriver.exe\"\n",
    "    service = EdgeService(executable_path=edge_driver_path)\n",
    "    return webdriver.Edge(service=service)\n",
    "\n",
    "# Hàm để thu thập dữ liệu từ một trang và lưu thông tin bài báo\n",
    "def extract_and_save_house_data(page_number):\n",
    "    driver = get_driver()\n",
    "    try:\n",
    "        print(f\"Đang lấy dữ liệu từ trang {page_number}...\")\n",
    "        driver.get(f'https://batdongsan.vn/ban-nha-ho-chi-minh/p{page_number}')\n",
    "        html_content = driver.page_source\n",
    "        soup = BeautifulSoup(html_content, 'html.parser')\n",
    "        \n",
    "        # Tìm tất cả các mục nhà\n",
    "        house_hrefs = []\n",
    "        house_items = soup.find_all(\"div\", class_=\"uk-grid uk-grid-small uk-grid-width-1-1\")\n",
    "        \n",
    "        for house in house_items:\n",
    "            name_divs = house.find_all(\"div\", class_=\"name\")\n",
    "            for name_div in name_divs:\n",
    "                a_tag = name_div.find(\"a\", href=True)\n",
    "                if a_tag:\n",
    "                    house_hrefs.append(a_tag['href'])\n",
    "        \n",
    "        print(f\"Tìm thấy {len(house_hrefs)} hrefs trên trang {page_number}.\")\n",
    "        \n",
    "        for index, href in enumerate(house_hrefs):\n",
    "            print(f\"Đang xử lý href {index + 1}/{len(house_hrefs)}: {href}\")\n",
    "            driver.get(href)\n",
    "            time.sleep(5)  # Dừng lại trong 5 giây để đảm bảo trang web đã được tải hoàn toàn.\n",
    "\n",
    "            house_html_content = driver.page_source\n",
    "            house_soup = BeautifulSoup(house_html_content, 'html.parser')\n",
    "\n",
    "            # Extract the title\n",
    "            title_element = house_soup.select_one('.project-global-object-block-003.information-custom .uk-panel-title span')\n",
    "            title = title_element.get_text(strip=True) if title_element else \"No Title\"\n",
    "\n",
    "            # Extract the price\n",
    "            price_element = house_soup.select_one('.project-global-object-block-003.information-custom .price')\n",
    "            price = price_element.get_text(strip=True) if price_element else \"No Price\"\n",
    "\n",
    "            # Extract the specific details\n",
    "            area, bedrooms, bathrooms, address, listing_id = \"No Area\", \"No Bedrooms\", \"No Bathrooms\", \"No Address\", \"No Listing ID\"\n",
    "            details_list = house_soup.select('.project-global-object-block-003.information-custom .uk-list li')\n",
    "            for detail in details_list:\n",
    "                strong_tag = detail.find('strong')\n",
    "                if strong_tag:\n",
    "                    key = strong_tag.get_text(strip=True)\n",
    "                    value = strong_tag.next_sibling.strip() if strong_tag.next_sibling else None\n",
    "                    if not value:\n",
    "                        value = strong_tag.find_next_sibling(string=True).strip() if strong_tag.find_next_sibling(string=True) else None\n",
    "                    if \"Diện tích\" in key:\n",
    "                        area = value\n",
    "                    elif \"Phòng ngủ\" in key:\n",
    "                        bedrooms = value\n",
    "                    elif \"Phòng WC\" in key:\n",
    "                        bathrooms = value\n",
    "                    elif \"Địa chỉ\" in key:\n",
    "                        address = value\n",
    "                    elif \"Mã tin\" in key:\n",
    "                        listing_id = value\n",
    "\n",
    "            # Extract the datetime for \"Ngày đăng:\"\n",
    "            date_element = house_soup.select_one('.project-global-object-block-003.information-custom .timeago')\n",
    "            date = date_element['datetime'] if date_element else \"No Date\"\n",
    "\n",
    "            # Locate the container for \"Nội dung tin đăng\"\n",
    "            content_element = house_soup.select_one('.project-global-object-block-003.block-custom .content')\n",
    "            # Extract the text content\n",
    "            if content_element:\n",
    "                content_text = content_element.get_text(separator=' ', strip=True)\n",
    "            else:\n",
    "                content_text = \"No content found\"\n",
    "            \n",
    "            # Tạo thư mục con cho số trang nếu nó chưa tồn tại.\n",
    "            sub_dir = os.path.join(output_dir, str(page_number))\n",
    "            if not os.path.exists(sub_dir):\n",
    "                os.makedirs(sub_dir)\n",
    "            \n",
    "            # Define file name\n",
    "            file_name = os.path.join(sub_dir, f\"{index + 1}.txt\")\n",
    "            \n",
    "            # Prepare file content\n",
    "            file_content = (\n",
    "                f\"Title: {title}\\n\"\n",
    "                f\"Price: {price}\\n\"\n",
    "                f\"Area: {area}\\n\"\n",
    "                f\"Bedrooms: {bedrooms}\\n\"\n",
    "                f\"Bathrooms: {bathrooms}\\n\"\n",
    "                f\"Address: {address}\\n\"\n",
    "                f\"Listing ID: {listing_id}\\n\"\n",
    "                f\"Date: {date}\\n\"\n",
    "                f\"Content:\\n{content_text}\\n\"\n",
    "            )\n",
    "            \n",
    "            # Write file content to file\n",
    "            with open(file_name, \"w\", encoding=\"utf-8\") as file:\n",
    "                file.write(file_content)\n",
    "            \n",
    "            print(f\"Đã lưu dữ liệu từ bài viết {href} vào tệp {file_name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Có lỗi xảy ra khi xử lý trang {page_number}: {str(e)}\")\n",
    "    finally:\n",
    "        driver.quit()\n",
    "\n",
    "total_pages = 500  # điều chỉnh con số này dựa trên số lượng trang mà bạn muốn thu thập.\n",
    "with ThreadPoolExecutor(max_workers=5) as executor:\n",
    "    futures = [executor.submit(extract_and_save_house_data, page_number) for page_number in range(1, total_pages + 1)]\n",
    "    for future in as_completed(futures):\n",
    "        try:\n",
    "            future.result()\n",
    "        except Exception as e:\n",
    "            print(f\"Có lỗi xảy ra khi xử lý một trang: {str(e)}\")\n",
    "\n",
    "print(\"Quá trình thu thập dữ liệu đã hoàn tất.\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0b310be1-fdf2-4c66-95fc-aecb6bcf464c",
   "metadata": {},
   "source": [
    "Đoạn output trên chỉ là 1 đoạn demo nhỏ ngắn về việc cào dữ liệu "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ebb6d3-826f-4eac-9f1c-3ac7d3d128c6",
   "metadata": {},
   "source": [
    "Thu thập dữ liệu từ trang web batdongsan.vn và tổ chức thông tin chi tiết về bất động sản vào một tệp CSV để dễ dàng quản lý và phân tích.Tự động hóa quá trình thu thập và xử lý dữ liệu từ nhiều trang web bất động sản. Tạo ra một cơ sở dữ liệu dễ dàng truy cập và sử dụng để phân tích thị trường bất động sản. Tối ưu hóa thời gian và công sức so với việc thủ công thu thập và nhập liệu. \n",
    "- Khởi tạo một danh sách rỗng data để lưu thông tin của các căn nhà từ các tệp tin văn bản.\n",
    "- Sử dụng os.listdir(output_dir) để lấy danh sách các tệp và thư mục trong output_dir\n",
    "- Duyệt qua từng page_number trong danh sách các thư mục (được tạo ra cho mỗi trang web đã cào).\n",
    "- Tạo đường dẫn đầy đủ tới mỗi tệp tin văn bản bằng cách kết hợp page_dir và file_name.\n",
    "- Kiểm tra nếu tệp không phải là ẩn và có đuôi mở rộng là .txt, mở tệp và đọc nội dung.\n",
    "- Mỗi tệp tin chứa thông tin về một căn nhà, được lưu theo định dạng cụ thể (ví dụ: Tiêu đề, Giá, Diện tích, Số phòng ngủ, ...).\n",
    "- Sử dụng các chỉ số của dòng để trích xuất thông tin tương ứng và lưu vào một dictionary house_info.\n",
    "- Mỗi house_info (dictionary) đại diện cho một bản ghi thông tin chi tiết của một căn nhà.\n",
    "- Thêm house_info vào danh sách data để tạo thành một danh sách các dictionaries chứa thông tin của tất cả các căn nhà."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a451583-5c0a-4988-aa8b-e152cdffb714",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error reading file data_crawled_batdongsan\\138\\17.txt: list index out of range\n",
      "Error reading file data_crawled_batdongsan\\250\\6.txt: list index out of range\n",
      "Dữ liệu đã được lưu vào tệp raw_data.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Thư mục chứa dữ liệu đã cào\n",
    "output_dir = \"data_crawled_batdongsan\"\n",
    "\n",
    "# Tạo danh sách để lưu trữ dữ liệu\n",
    "data = []\n",
    "\n",
    "# Duyệt qua tất cả các tệp đã lưu trong thư mục\n",
    "for page_number in os.listdir(output_dir):\n",
    "    page_dir = os.path.join(output_dir, page_number)\n",
    "    if os.path.isdir(page_dir) and not page_number.startswith('.'):\n",
    "        for file_name in os.listdir(page_dir):\n",
    "            file_path = os.path.join(page_dir, file_name)\n",
    "            if not file_name.startswith('.') and file_path.endswith('.txt'):\n",
    "                try:\n",
    "                    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "                        lines = file.readlines()\n",
    "                        # Khởi tạo dictionary để lưu trữ thông tin của mỗi căn nhà\n",
    "                        house_info = {\n",
    "                            \"Title\": lines[0].replace(\"Title: \", \"\").strip(),\n",
    "                            \"Price\": lines[1].replace(\"Price: \", \"\").strip(),\n",
    "                            \"Area\": lines[2].replace(\"Area: \", \"\").strip(),\n",
    "                            \"Bedrooms\": lines[3].replace(\"Bedrooms: \", \"\").strip(),\n",
    "                            \"Bathrooms\": lines[4].replace(\"Bathrooms: \", \"\").strip(),\n",
    "                            \"Address\": lines[5].replace(\"Address: \", \"\").strip(),\n",
    "                            \"Listing ID\": lines[6].replace(\"Listing ID: \", \"\").strip(),\n",
    "                            \"Date\": lines[7].replace(\"Date: \", \"\").strip(),\n",
    "                            \"Content\": \"\".join(lines[9:]).strip()  # Nội dung bắt đầu từ dòng thứ 10\n",
    "                        }\n",
    "                        data.append(house_info)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error reading file {file_path}: {e}\")\n",
    "\n",
    "# Tạo DataFrame từ danh sách dữ liệu\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Lưu DataFrame vào tệp CSV\n",
    "csv_file_path = \"raw_data.csv\"\n",
    "df.to_csv(csv_file_path, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(f\"Dữ liệu đã được lưu vào tệp {csv_file_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
